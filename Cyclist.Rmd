---
title: "Case Study 1: How does a bike-share navigate speedy success?"
author: "Khalid MD Ashik"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
##### This analysis is based on the Divvy case study "'Sophisticated, Clear, and Polished’: Divvy and Data Visualization" written by Kevin Hartman (found here: https://artscience.blog/home/divvy-dataviz-case-study). The purpose of this script is to consolidate downloaded Divvy data into a single dataframe and then conduct simple analysis to help answer the key question: “In what ways do members and casual riders use Divvy bikes differently?”

#### In this case study, I have performed data analysis for a fictional bike-share company in order to help them attract more riders. Along the way, I performed numerous real-world tasks of a junior data analyst by following the steps of the data analysis process: Ask, Prepare, Process, Analyze, Share, and Act.

# # # # # # # # # # # # # # # # # # # # # # # 
#### Installed required packages
#### tidyverse for data import and wrangling
#### lubridate for date functions
#### ggplot for visualization
# # # # # # # # # # # # # # # # # # # # # # #

```{r}
install.packages("tidyverse", repos = "http://cran.us.r-project.org")
install.packages("lubridate", repos = "http://cran.us.r-project.org")
install.packages("ggplot2", repos = "http://cran.us.r-project.org")
install.packages("dplyr", repos = "http://cran.us.r-project.org")
```
```{r}
library(tidyverse)
library(lubridate)
library(ggplot2)
library(dplyr)
getwd()
setwd("/Users/rising.volkan007/Desktop/q1_2020")
```

### STEP 1: COLLECTED DATA

#### Uploaded Divvy  datasets for the year of 2022 (csv files) here

```{r}
q1_2022 <- read_csv("202210-divvy-tripdata.csv", show_col_types = FALSE)
q2_2022 <- read_csv("202209-divvy-tripdata.csv", show_col_types = FALSE)
q3_2022 <- read_csv("202208-divvy-tripdata.csv", show_col_types = FALSE)
q4_2022 <- read_csv("202207-divvy-tripdata.csv", show_col_types = FALSE)
q5_2022 <- read_csv("202206-divvy-tripdata.csv", show_col_types = FALSE)
q6_2022 <- read_csv("202205-divvy-tripdata.csv", show_col_types = FALSE)
q7_2022 <- read_csv("202204-divvy-tripdata.csv", show_col_types = FALSE)
q8_2022 <- read_csv("202203-divvy-tripdata.csv", show_col_types = FALSE)
q9_2022 <- read_csv("202201-divvy-tripdata.csv", show_col_types = FALSE)

```

### STEP 2: WRANGLE DATA AND COMBINE INTO A SINGLE FILE

#### Compared column names each of the files
#### While the names don't have to be in the same order, they DO need to match perfectly before we can use a command to join them into one file

```{r}
colnames(q1_2022)
colnames(q2_2022)
colnames(q3_2022)
colnames(q4_2022)
colnames(q5_2022)
colnames(q6_2022)
```
#### Inspected the dataframes and look for incongruencies
```{r include=FALSE}
str(q1_2022)
str(q2_2022)
str(q3_2022)
str(q4_2022)
str(q5_2022)
str(q6_2022)
str(q7_2022)
str(q8_2022)
str(q9_2022)
```

#### Converted ride_id and rideable_type to character so that they can stack correctly

```{r}
q1_2022 <- mutate(q1_2022, ride_id= as.character(ride_id), rideable_type=as.character(rideable_type))

q2_2022 <- mutate(q2_2022, ride_id= as.character(ride_id), rideable_type=as.character(rideable_type))

q3_2022 <- mutate(q3_2022, ride_id= as.character(ride_id), rideable_type=as.character(rideable_type))

q4_2022 <- mutate(q4_2022, ride_id= as.character(ride_id), rideable_type=as.character(rideable_type))

q5_2022 <- mutate(q5_2022, ride_id= as.character(ride_id), rideable_type=as.character(rideable_type))

q6_2022 <- mutate(q6_2022, ride_id= as.character(ride_id), rideable_type=as.character(rideable_type))

q7_2022 <- mutate(q7_2022, ride_id= as.character(ride_id), rideable_type=as.character(rideable_type))

q8_2022 <- mutate(q8_2022, ride_id= as.character(ride_id), rideable_type=as.character(rideable_type))

q9_2022 <- mutate(q9_2022, ride_id= as.character(ride_id), rideable_type=as.character(rideable_type))
```

#### Stack individual quarter's data frames into one big data frame

```{r}
all_trips <- bind_rows(q1_2022, q2_2022, q3_2022, q4_2022,q5_2022,q6_2022,q7_2022,q8_2022,q9_2022)
```

#### Removed lat, long data was dropped beginning in 2022

```{r}
all_trips <- all_trips %>% 
  select(-c(start_lat,start_lng,end_lat,end_lng))
```


### STEP 3: CLEAN UP AND ADD DATA TO PREPARE FOR ANALYSIS

#### Inspect the new table that has been created

```{r}
colnames(all_trips)  #List of column names
nrow(all_trips)  #How many rows are in data frame?
dim(all_trips)  #Dimensions of the data frame?
head(all_trips)  #See the first 6 rows of data frame.  Also tail(all_trips)
tail(all_trips)
str(all_trips)  #See list of columns and data types (numeric, character, etc)
summary(all_trips)  #Statistical summary of data. Mainly for numerics

```
#### Checked to make sure the proper number of observations were reassigned

```{r}
table(all_trips$member_casual)
```

#### Added columns that list the date, month, day, and year of each ride
#### This will allow us to aggregate ride data for each month, day, or year ... before completing these operations we could only aggregate at the ride level
#### https://www.statmethods.net/input/dates.html more on date formats in R found at that link

```{r}
all_trips$date <- as.Date(all_trips$started_at) #The default format is yyyy-mm-dd
all_trips$month <- format(as.Date(all_trips$date), "%m")
all_trips$day <- format(as.Date(all_trips$date), "%d")
all_trips$year <- format(as.Date(all_trips$date), "%Y")
all_trips$day_of_week <- format(as.Date(all_trips$date), "%A")

```

#### Added a "ride_length" calculation to all_trips (in seconds)
#### https://stat.ethz.ch/R-manual/R-devel/library/base/html/difftime.html

```{r}
all_trips$ride_length <- difftime(all_trips$ended_at,all_trips$started_at)
```

#### Inspect the structure of the columns

```{r}
str(all_trips)
```
#### Convert "ride_length" from Factor to numeric so we can run calculations on the data is.factor(all_trips$ride_length)

```{r}
all_trips$ride_length <- as.numeric(as.character(all_trips$ride_length))
is.numeric(all_trips$ride_length)

```

#### Removed "bad" data
#### The dataframe includes a few hundred entries when bikes were taken out of docks and checked for quality by Divvy or ride_length was negative
#### We will create a new version of the dataframe (v2) since data is being removed
#### https://www.datasciencemadesimple.com/delete-or-drop-rows-in-r-with-conditions-2/

```{r}
all_trips_v2 <- all_trips[!(all_trips$start_station_name == "HQ QR" | all_trips$ride_length<0),]
```



### STEP 4: CONDUCT DESCRIPTIVE ANALYSIS

#### Descriptive analysis on ride_length (all figures in seconds)

```{r}
mean(all_trips_v2$ride_length) #straight average (total ride length / rides)
median(all_trips_v2$ride_length) #midpoint number in the ascending array of ride lengths
max(all_trips_v2$ride_length) #longest ride
min(all_trips_v2$ride_length) #shortest ride

```


#### I had condensed the four lines above to one line using summary() on the specific attribute

```{r}
summary(all_trips_v2$ride_length)
```

#### Compared members and casual users

```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = mean)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = median)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = max)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = min)

```


#### See the average ride time by each day for members vs casual users

```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
```
#### Notice that the days of the week are out of order. Let's fix that

```{r}
all_trips_v2$day_of_week <- ordered(all_trips_v2$day_of_week, levels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))

```

#### Now, let's run the average ride time by each day for members vs casual users

```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)

```
#### analyze ridership data by type and weekday

```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>%  #creates weekday field using wday()
  group_by(member_casual, weekday) %>%  #groups by usertype and weekday
  summarise(number_of_rides = n()							#calculates the number of rides and average duration 
  ,average_duration = mean(ride_length)) %>% 		# calculates the average duration
  arrange(member_casual, weekday)	
```


#### Let's visualize the number of rides by rider type

```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")

```

#### Let's create a visualization for average duration

```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")

```


### STEP 5: EXPORT SUMMARY FILE FOR FURTHER ANALYSIS

#### Created a csv file that we will visualize in Excel, Tableau, or my presentation software
##### N.B.: This file location is for a Mac. If you are working on a PC, change the file location accordingly (most likely "C:\Users\YOUR_USERNAME\Desktop\...") to export the data. You can read more here: https://datatofish.com/export-dataframe-to-csv-in-r/

```{r}
counts <- aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
write.csv(counts, file = '~/Desktop/q1_2020/avg_ride_length.csv')

```

